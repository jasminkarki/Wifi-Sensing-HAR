{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math, os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from keras.layers.convolutional import Conv1D\n",
    "# from keras.layers.convolutional import MaxPooling1D\n",
    "# from keras.utils import to_categorical\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, Conv2D, MaxPooling1D,MaxPooling2D, LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_of_CSI(directory):\n",
    "    # Create empty DataFrames for walk, up, and jog\n",
    "    df_walk = pd.DataFrame()\n",
    "    df_up = pd.DataFrame()\n",
    "    df_jog = pd.DataFrame()\n",
    "\n",
    "    # Loop through each file in the directory\n",
    "    for file in os.listdir(directory):\n",
    "        # Check if the file is a CSV file and contains \"walk\", \"up\", or \"jog\" in the name\n",
    "        if file.endswith(\".csv\") and (\"walk\" in file or \"up\" in file or \"jog\" in file):\n",
    "            # Read the CSV file and extract the CSI_DATA column\n",
    "            file_path = os.path.join(directory, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            csi_rows_raw = []\n",
    "\n",
    "            ## Filtering can be done using\n",
    "            df = df[(df[\"bandwidth\"]==0)]# & (df[\"secondary_channel\"]==1)]\n",
    "\n",
    "            ## Ignore first few and last few seconds data\n",
    "            for one_row in df['CSI_DATA'].iloc[40:-40]:\n",
    "                one_row = one_row.strip(\"[]\")\n",
    "                csi_row_raw = [int(x) for x in one_row.split(\" \") if x != '']\n",
    "                csi_rows_raw.append(csi_row_raw)\n",
    "        \n",
    "            # Convert the list of lists to a DataFrame and append it to the appropriate DataFrame based on the file name\n",
    "            csi_df = pd.DataFrame(csi_rows_raw)\n",
    "\n",
    "            # Check which dataframe we are working on and concat the data\n",
    "            if \"walk\" in file:\n",
    "                df_walk = pd.concat([df_walk, csi_df], axis=0)\n",
    "            elif \"up\" in file:\n",
    "                df_up = pd.concat([df_up, csi_df], axis=0)\n",
    "            else:\n",
    "                df_jog = pd.concat([df_jog, csi_df], axis=0)\n",
    "    return df_walk, df_up, df_jog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path where the CSV files are located\n",
    "directory = \"C:\\\\Users\\\\Dell\\\\Documents\\\\Wifi-Sensing-HAR\\\\data\\\\our_data\"\n",
    "\n",
    "walk_df, up_df, jog_df = dataframe_of_CSI(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of entries found is: \n",
      "29093 3387 63015\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of entries found is: \")\n",
    "print(len(walk_df),len(up_df),len(jog_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract Amplitude and Phase from the dataframe\n",
    "def convert_csi_to_amplitude_phase(df):\n",
    "    total_amplitudes = []\n",
    "    total_phases = []\n",
    "\n",
    "    for i, value in enumerate(df.values):\n",
    "        imaginary = []\n",
    "        real = []\n",
    "        amplitudes = [] \n",
    "        phases = []\n",
    "\n",
    "        csi_one_row_lst = value.tolist()\n",
    "\n",
    "         # Create list of imaginary and real numbers from CSI\n",
    "        [imaginary.append(csi_one_row_lst[item]) if item%2==0 else real.append(csi_one_row_lst[item]) for item in range(len(csi_one_row_lst))]\n",
    "\n",
    "        # Transform imaginary and real into amplitude and phase\n",
    "        val = int(len(csi_one_row_lst)//2)\n",
    "        for k in range(val):\n",
    "            amplitudes.append(round(math.sqrt(float(imaginary[k])** 2 + float(real[k])** 2),4))\n",
    "            phases.append(round(math.atan2(float(imaginary[k]), float(real[k])),4))\n",
    "        total_amplitudes.append(np.array(amplitudes))\n",
    "        total_phases.append(np.array(phases))\n",
    "    \n",
    "    total_amplitudes_df = pd.DataFrame(total_amplitudes)\n",
    "    total_phases_df = pd.DataFrame(total_phases)\n",
    "\n",
    "        \n",
    "    return total_amplitudes_df, total_phases_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amplitude and Phase of Walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract walk amplitude and phase\n",
    "walk_amplitudes_df, walk_phases_df = convert_csi_to_amplitude_phase(walk_df)\n",
    "\n",
    "## Here, based on sig_mode, 802.11a/g/n received. Here we receive both 802.11a/g and 802.11n\n",
    "## So, either 52 or 56 total sub-carrier would be useful. The first 4 and the last 4 are rejected as null guard.\n",
    "\n",
    "\n",
    "## Amplitude\n",
    "walk_df1_amps = walk_amplitudes_df.iloc[:,5:32]  # 6:32 for 802.11ag 4:32 for 802.11n\n",
    "walk_df2_amps = walk_amplitudes_df.iloc[:,33:60] # 33:59 for 802.11ag 33:61 for 802.11n\n",
    "\n",
    "walk_df_amps_final = pd.concat([walk_df1_amps, walk_df2_amps],axis=1)\n",
    "\n",
    "\n",
    "## Phase\n",
    "walk_df1_phase = walk_amplitudes_df.iloc[:,5:32]  # 6:32 for 802.11ag 4:32 for 802.11n\n",
    "walk_df2_phase = walk_amplitudes_df.iloc[:,33:60] # 33:59 for 802.11ag 33:61 for 802.11n\n",
    "\n",
    "walk_df_phase_final = pd.concat([walk_df1_phase, walk_df2_phase],axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplitude and Phase of Jogging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract jog amplitude and phase\n",
    "jog_amplitudes_df, jog_phases_df = convert_csi_to_amplitude_phase(jog_df)\n",
    "\n",
    "## Amplitude\n",
    "jog_df1_amps = jog_amplitudes_df.iloc[:,5:32]  # 6:32 for 802.11ag 4:32 for 802.11n\n",
    "jog_df2_amps = jog_amplitudes_df.iloc[:,33:60] # 33:59 for 802.11ag 33:61 for 802.11n\n",
    "\n",
    "jog_df_amps_final = pd.concat([jog_df1_amps, jog_df2_amps],axis=1)\n",
    "\n",
    "\n",
    "## Phase\n",
    "jog_df1_phase = jog_amplitudes_df.iloc[:,5:32]  # 6:32 for 802.11ag 4:32 for 802.11n\n",
    "jog_df2_phase = jog_amplitudes_df.iloc[:,33:60] # 33:59 for 802.11ag 33:61 for 802.11n\n",
    "\n",
    "jog_df_phase_final = pd.concat([jog_df1_phase, jog_df2_phase],axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplitude and Phase of Stand Up Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract up amplitude and phase\n",
    "up_amplitudes_df, up_phases_df = convert_csi_to_amplitude_phase(up_df)\n",
    "\n",
    "## Amplitude\n",
    "up_df1_amps = up_amplitudes_df.iloc[:,5:32]  # 6:32 for 802.11ag 4:32 for 802.11n\n",
    "up_df2_amps = up_amplitudes_df.iloc[:,33:60] # 33:59 for 802.11ag 33:61 for 802.11n\n",
    "\n",
    "up_df_amps_final = pd.concat([up_df1_amps, up_df2_amps],axis=1)\n",
    "\n",
    "\n",
    "## Phase\n",
    "up_df1_phase = up_amplitudes_df.iloc[:,5:32]  # 6:32 for 802.11ag 4:32 for 802.11n\n",
    "up_df2_phase = up_amplitudes_df.iloc[:,33:60] # 33:59 for 802.11ag 33:61 for 802.11n\n",
    "\n",
    "up_df_phase_final = pd.concat([up_df1_phase, up_df2_phase],axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving Average of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving average of the data\n",
    "def moving_average(df, window_size):\n",
    "    \"\"\"\"\n",
    "    Compute the moving average with a window of size specified\n",
    "    \"\"\"\n",
    "\n",
    "    rolling_mean = df.rolling(window=window_size).mean()\n",
    "    downsampled = rolling_mean.iloc[window_size::window_size, :]\n",
    "    return downsampled\n",
    "\n",
    "\n",
    "## Set moving average window of desired size \n",
    "window_size = 1\n",
    "mov_avg_walk_amps_df = moving_average(walk_df_amps_final,window_size)\n",
    "mov_avg_walk_phase_df = moving_average(walk_df_phase_final,window_size)\n",
    "mov_avg_jog_amps_df = moving_average(jog_df_amps_final,window_size)\n",
    "mov_avg_jog_phase_df = moving_average(jog_df_phase_final,window_size)\n",
    "mov_avg_up_amps_df = moving_average(up_df_amps_final,window_size)\n",
    "mov_avg_up_phase_df = moving_average(up_df_phase_final,window_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select n samples of data for input to the system as a flattened matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data_portion(dataFrm,select_size):\n",
    "    selected_df_list = []\n",
    "    for item in range(0,len(dataFrm)-select_size, select_size):\n",
    "        selected_df = dataFrm.iloc[item:item+select_size].to_numpy().flatten()\n",
    "        selected_df_list.append(selected_df)\n",
    "    selected_df = pd.DataFrame(selected_df_list)\n",
    "    return selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mov_avg_walk_amps_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_walk \u001b[39m=\u001b[39m select_data_portion(mov_avg_walk_amps_df, \u001b[39m50\u001b[39m)\n\u001b[0;32m      2\u001b[0m X_jog \u001b[39m=\u001b[39m select_data_portion(mov_avg_jog_amps_df, \u001b[39m50\u001b[39m)\n\u001b[0;32m      3\u001b[0m X_up \u001b[39m=\u001b[39m select_data_portion(mov_avg_up_amps_df, \u001b[39m50\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mov_avg_walk_amps_df' is not defined"
     ]
    }
   ],
   "source": [
    "X_walk = select_data_portion(mov_avg_walk_amps_df, 50)\n",
    "X_jog = select_data_portion(mov_avg_jog_amps_df, 50)\n",
    "X_up = select_data_portion(mov_avg_up_amps_df, 50)\n",
    "# X_walk = select_data_portion(walk_df_amps_final, 50)\n",
    "# X_jog = select_data_portion(jog_df_amps_final, 50)\n",
    "# X_up = select_data_portion(up_df_amps_final, 50)\n",
    "\n",
    "X_training = pd.concat([X_walk,X_jog,X_up],axis=0,ignore_index=True)\n",
    "# X_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 2., 2., 2.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_walk = np.zeros(len(X_walk))\n",
    "y_jog = np.ones(len(X_jog))\n",
    "y_up = np.ones(len(X_up))+1\n",
    "\n",
    "y_training = np.concatenate([y_walk, y_jog, y_up],axis=0)\n",
    "y_training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_scaling(df):\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(df)\n",
    "    scaled_data = scaler.transform(df)\n",
    "    return scaled_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for Visualization\n",
    "\n",
    "Here we have 52 to 54 usable columns. Not all columns/subcarriers are useful. So, we need to select only the useful ones. This can be done by PCA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA with arbitary n_components or variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca(X, n_components):\n",
    "    \"\"\"\n",
    "    Perform PCA on the data.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X)\n",
    "    new_sample = pca.transform(X)\n",
    "    return pca, new_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = perform_scaling(X_training)\n",
    "pca_obj, pca_X = perform_pca(scaled_X, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1908, 1033)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pca_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of components used after PCA : 1033\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of components used after PCA : {pca_obj.n_components_}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_data(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data into training and testing sets.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify = y, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_X, y_training)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train SVM model using the training data.\n",
    "    \"\"\"\n",
    "    # svm = SVC(C=10, gamma=0.001)\n",
    "    svm = SVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    return svm\n",
    "\n",
    "\n",
    "def train_knn(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train KNN model using the training data.\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn\n",
    "\n",
    "def train_model(model_type, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train model of given type using the training data.\n",
    "    \"\"\"\n",
    "    if model_type == 'svm':\n",
    "        model = train_svm(X_train, y_train)\n",
    "    elif model_type == 'knn':\n",
    "        model = train_knn(X_train, y_train)\n",
    "    # elif model_type == 'cnn':\n",
    "    #     model = train_cnn(X_train, y_train)\n",
    "    # elif model_type == 'lstm':\n",
    "    #     model = train_lstm(X_train, y_train)\n",
    "    else:\n",
    "        raise ValueError('Invalid model type.')\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model, X_test):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the testing data.\n",
    "    \"\"\" \n",
    "    label = model.predict(X_test)\n",
    "    return label\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the testing data.\n",
    "    \"\"\" \n",
    "    score = model.score(X_test, y_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9014675052410901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[119,  23,   0],\n",
       "       [  8, 308,   0],\n",
       "       [  7,   9,   3]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = train_model('svm', X_train, y_train)\n",
    "y_pred = test_model(svm, X_test)\n",
    "print(evaluate_model(svm, X_test, y_test))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7987421383647799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 64,  84,   5],\n",
       "       [  1, 311,   0],\n",
       "       [  2,   4,   6]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = train_model('knn', X_train, y_train)\n",
    "y_pred = test_model(svm, X_test)\n",
    "print(evaluate_model(svm, X_test, y_test))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.662 total time=   3.3s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.664 total time=   2.7s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.664 total time=   2.6s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.661 total time=   2.6s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.661 total time=   2.3s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.662 total time=   2.3s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.664 total time=   2.2s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.664 total time=   2.2s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.661 total time=   2.3s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.661 total time=   2.2s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.662 total time=   2.2s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.664 total time=   2.4s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.664 total time=   2.3s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.661 total time=   2.2s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.661 total time=   2.2s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.787 total time=   1.4s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.752 total time=   1.4s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.755 total time=   1.4s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.797 total time=   1.4s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.787 total time=   1.3s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.780 total time=   0.9s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.811 total time=   0.9s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.801 total time=   0.9s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.790 total time=   0.9s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.797 total time=   0.9s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.662 total time=   2.3s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.664 total time=   2.3s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.664 total time=   2.3s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.661 total time=   2.3s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.661 total time=   2.3s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.662 total time=   2.2s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.664 total time=   2.1s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.664 total time=   2.2s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.661 total time=   2.2s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.661 total time=   3.2s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.662 total time=   2.7s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.664 total time=   2.1s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.664 total time=   3.1s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.661 total time=   3.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.661 total time=   2.4s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.885 total time=   1.9s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.888 total time=   3.4s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.853 total time=   2.9s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.860 total time=   2.4s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.885 total time=   2.5s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.829 total time=   1.4s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.878 total time=   1.7s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.836 total time=   1.2s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.846 total time=   1.2s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.881 total time=   1.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.662 total time=   3.2s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.664 total time=   3.7s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.664 total time=   4.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.661 total time=   4.9s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.661 total time=   2.8s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.662 total time=   2.2s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.664 total time=   2.1s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.664 total time=   2.2s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.661 total time=   2.2s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.661 total time=   2.1s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.662 total time=   2.1s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.664 total time=   2.2s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.664 total time=   2.2s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.661 total time=   2.1s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.661 total time=   2.3s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.895 total time=   1.7s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.888 total time=   1.6s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.857 total time=   1.7s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.881 total time=   1.6s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.892 total time=   1.6s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.875 total time=   1.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.899 total time=   1.4s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.839 total time=   1.2s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.881 total time=   1.1s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.881 total time=   1.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.662 total time=   2.3s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.664 total time=   2.2s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.664 total time=   2.3s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.661 total time=   2.3s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.661 total time=   2.6s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.662 total time=   2.1s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.664 total time=   2.2s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.664 total time=   2.1s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.661 total time=   2.1s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.661 total time=   2.3s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.662 total time=   2.2s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.664 total time=   2.1s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.664 total time=   2.1s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.661 total time=   2.3s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.661 total time=   2.1s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.895 total time=   1.6s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.888 total time=   1.7s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.857 total time=   1.7s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.881 total time=   1.7s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.892 total time=   1.6s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.871 total time=   1.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.895 total time=   1.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.836 total time=   0.9s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.881 total time=   0.9s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.885 total time=   1.0s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.662 total time=   2.3s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.664 total time=   2.4s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.664 total time=   2.2s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.661 total time=   2.2s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.661 total time=   2.4s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.662 total time=   2.1s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.664 total time=   2.1s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.664 total time=   2.1s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.661 total time=   2.1s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.661 total time=   2.2s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.662 total time=   2.2s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.664 total time=   2.1s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.664 total time=   2.2s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.661 total time=   2.1s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.661 total time=   2.1s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.895 total time=   1.6s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.888 total time=   1.7s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.857 total time=   1.6s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.881 total time=   1.8s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.892 total time=   1.7s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.871 total time=   1.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.895 total time=   1.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.836 total time=   0.9s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.881 total time=   0.9s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.885 total time=   1.0s\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "SVC(C=10, gamma=0.001)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m grid_predictions \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     22\u001b[0m \u001b[39m# print classification report\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test, grid_predictions))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "\n",
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.88      0.87       153\n",
      "         1.0       0.94      0.96      0.95       312\n",
      "         2.0       1.00      0.17      0.29        12\n",
      "\n",
      "    accuracy                           0.92       477\n",
      "   macro avg       0.94      0.67      0.70       477\n",
      "weighted avg       0.92      0.92      0.91       477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, gamma=0.001)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harsense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
